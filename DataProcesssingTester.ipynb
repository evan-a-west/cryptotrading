{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd02db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, progress\n",
    "from dask import delayed\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:59267' processes=8 threads=16, memory=7.45 GiB>"
      ],
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:59267</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>8</li>\n  <li><b>Cores: </b>16</li>\n  <li><b>Memory: </b>7.45 GiB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "client = Client(n_workers=8, threads_per_worker=2, memory_limit='1GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(\"ProcessedData/DOGE_2021-04-16.csv\")\n",
    "df[\"datetime\"] = dd.to_datetime(df[\"datetime\"])\n",
    "df[\"datetimeNotTheIndex\"] = dd.to_datetime(\n",
    "    df[\"datetimeNotTheIndex\"])\n",
    "\n",
    "df = df.set_index(\"datetime\", sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['ask_price', 'bid_price', 'mark_price', 'high_price', 'low_price',\n       'open_price', 'volume', 'datetimeNotTheIndex',\n       'mark_price_10T_velocity', 'mark_price_30T_velocity',\n       'mark_price_60T_velocity', 'mark_price_180T_velocity',\n       'mark_price_720T_velocity', 'mark_price_1440T_velocity',\n       'mark_price_4320T_velocity', 'mark_price_10080T_velocity',\n       'mark_price_21600T_velocity', 'mark_price_10T_mean',\n       'mark_price_30T_mean', 'mark_price_60T_mean', 'mark_price_180T_mean',\n       'mark_price_720T_mean', 'mark_price_1440T_mean',\n       'mark_price_4320T_mean', 'mark_price_10080T_mean',\n       'mark_price_21600T_mean', 'mark_price_10T_std', 'mark_price_30T_std',\n       'mark_price_60T_std', 'mark_price_180T_std', 'mark_price_720T_std',\n       'mark_price_1440T_std', 'mark_price_4320T_std', 'mark_price_10080T_std',\n       'mark_price_21600T_std', 'spread',\n       'mark_price_10T_acceleration_for_10T_velocity',\n       'mark_price_30T_acceleration_for_30T_velocity',\n       'mark_price_60T_acceleration_for_60T_velocity',\n       'mark_price_180T_acceleration_for_180T_velocity',\n       'mark_price_720T_acceleration_for_720T_velocity',\n       'mark_price_1440T_acceleration_for_1440T_velocity',\n       'mark_price_4320T_acceleration_for_4320T_velocity',\n       'mark_price_10080T_acceleration_for_10080T_velocity',\n       'mark_price_21600T_acceleration_for_21600T_velocity', 'min', 'max',\n       'minmax'],\n      dtype='object')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Delayed('int-71b39f18-4798-407e-8595-bf16bed3f0b8'), 48)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = ['mark_price', 'ask_price', 'bid_price', 'spread',\n",
    "                    'mark_price_10T_velocity', 'mark_price_60T_velocity',\n",
    "                    'mark_price_1440T_velocity', 'mark_price_10T_mean',\n",
    "                    'mark_price_60T_mean', 'mark_price_1440T_mean', 'mark_price_10T_std',\n",
    "                    'mark_price_60T_std', 'mark_price_1440T_std',\n",
    "                    'mark_price_10T_acceleration_for_10T_velocity',\n",
    "                    'mark_price_60T_acceleration_for_60T_velocity', \"datetimeNotTheIndex\"]\n",
    "\n",
    "df_train = df[training_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_resampled = df_train.compute().resample(rule='30s', label='right', closed='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# MinMax GLOBALS\n",
    "##################################\n",
    "# Flags to indicate min/max columns\n",
    "MIN_FLAG = 1\n",
    "MAX_FLAG = 2\n",
    "NEITHER_FLAG = 0\n",
    "# Threshold percent for determining when to keep/delete a min or max value\n",
    "# i.e. if .5 is put here, that translates to .5% in the code\n",
    "THRESHOLD_PERCENTAGE = .25\n",
    "SIGNAL_MAX_ORDER = 25\n",
    "SIGNAL_MIN_ORDER = 25\n",
    "\n",
    "# Gapsize for spliting data\n",
    "GAP_SIZE_MINUTES = 7\n",
    "RESAMPLE_PERIOD = '30S'\n",
    "INTERPOLATION_METHOD = 'linear'\n",
    "\n",
    "\n",
    "def splitDataByGaps(data):\n",
    "    # Covert from a datetime index back to a 'standard' index for use the for loop, below. This seems to be the easier fix. Datetime index does not work for the iloc\n",
    "    deltas = data.set_index(np.array(range(0, data.shape[0], 1)))[\n",
    "        \"datetimeNotTheIndex\"].diff()[0:]\n",
    "    gaps = deltas[deltas > timedelta(minutes=GAP_SIZE_MINUTES)]\n",
    "\n",
    "    data_split = list()\n",
    "    start_index = 0\n",
    "    for gap_index in gaps.index:\n",
    "        data_split.append(data.iloc[start_index:gap_index, :])\n",
    "        start_index = gap_index\n",
    "    # Append the final split\n",
    "    data_split.append(data.iloc[start_index:, :])\n",
    "\n",
    "    return data_split\n",
    "\n",
    "def resampleAndInterpolate(data):\n",
    "    resample_index = pd.date_range(\n",
    "        start=data.index[0],  end=data.index[-1], freq=RESAMPLE_PERIOD)\n",
    "    dummy_data = pd.DataFrame(\n",
    "        np.NAN, index=resample_index, columns=data.columns)\n",
    "    intermediateResample = data.combine_first(\n",
    "        dummy_data).interpolate('time')\n",
    "    finalResample = intermediateResample.resample(\n",
    "        rule=RESAMPLE_PERIOD, origin=data.index[0]).asfreq()\n",
    "    # data = data.interpolate(self.INTERPOLATION_METHOD)\n",
    "    return finalResample\n",
    "\n",
    "def generateMinmMaxColumn(pd_data):\n",
    "    pd_data = generateMinmaxColumn(pd_data)\n",
    "    pd_data = minmaxThresholdCheck(pd_data)\n",
    "    return pd_data\n",
    "\n",
    "def generateMinmaxColumn(pd_data):\n",
    "    #######################################\n",
    "    # Label data, for finding local maximum and minima.\n",
    "    # New columns: Min, Max and Minmax\n",
    "    #######################################\n",
    "    pd_data['min'] = pd_data.mark_price[(pd_data.mark_price.shift(\n",
    "        1) > pd_data.mark_price) & (pd_data.mark_price.shift(-1) > pd_data.mark_price)]\n",
    "    pd_data['max'] = pd_data.mark_price[(pd_data.mark_price.shift(\n",
    "        1) < pd_data.mark_price) & (pd_data.mark_price.shift(-1) < pd_data.mark_price)]\n",
    "\n",
    "    # Min and Max column should not contain NANs\n",
    "    pd_data['min'] = pd_data['min'].fillna(0)\n",
    "    pd_data['max'] = pd_data['max'].fillna(0)\n",
    "\n",
    "    # Minmax column should be 0 for neither min nor max\n",
    "    pd_data['minmax'] = NEITHER_FLAG\n",
    "\n",
    "    # Minmax column should be 1 for min\n",
    "    # pd_data.loc[pd_data['min'] != 0, 'minmax'] = self.MIN_FLAG\n",
    "    minData = signal.argrelmin(\n",
    "        data=pd_data[\"mark_price\"].values.compute(), order=SIGNAL_MAX_ORDER, mode='clip')\n",
    "    pd_data.compute().iloc[minData[0], pd_data.columns.get_loc(\n",
    "        \"minmax\")] = MIN_FLAG\n",
    "\n",
    "    # Minmax column should be 2 for max\n",
    "    # pd_data.loc[pd_data['max'] != 0, 'minmax'] = self.MAX_FLAG\n",
    "    maxData = signal.argrelmax(\n",
    "        data=pd_data[\"mark_price\"].values.compute(), order=SIGNAL_MIN_ORDER, mode='clip')\n",
    "    pd_data.compute().iloc[maxData[0], pd_data.columns.get_loc(\n",
    "        \"minmax\")] = MAX_FLAG\n",
    "\n",
    "    return pd_data\n",
    "\n",
    "# @jit(nopython=True, parallel=True)\n",
    "def minmaxThresholdCheck(pd_data):\n",
    "    # grab just the rows with non-zero min and max values for easy comparison\n",
    "    subset = pd_data.loc[(pd_data['minmax'] != NEITHER_FLAG)].compute()\n",
    "\n",
    "    # For each row in subset, check if each subsequent pair of of min/max values pass the given threshold\n",
    "    subset_row_counter = 0\n",
    "    subsetSize = subset.shape[0]\n",
    "    while(subset_row_counter < subsetSize):\n",
    "        diff_greater_than_threshold = False\n",
    "        # Because Subset rows are removed in this loop, need to recheck the size here as an ending condition.\n",
    "        # Note that subset_row_counter+1 is needed because we compare the current subset row against the next subset row\n",
    "        while (not diff_greater_than_threshold) and (subset_row_counter+1 < subsetSize):\n",
    "            current_minmax = subset.iloc[subset_row_counter]\n",
    "            current_minmax_value = float(current_minmax['mark_price'])\n",
    "            current_minmax_index = pd_data[pd_data['datetimeNotTheIndex']\n",
    "                                            == current_minmax['datetimeNotTheIndex']].index[0]\n",
    "            next_minmax = subset.iloc[subset_row_counter+1]\n",
    "            next_minmax_value = float(next_minmax['mark_price'])\n",
    "            next_minmax_index = pd_data[pd_data['datetimeNotTheIndex']\n",
    "                                        == next_minmax['datetimeNotTheIndex']].index[0]\n",
    "\n",
    "            # If the current va lue and next value in the subset are different (i.e. if one is a MIN and the other is a MAX), then run threshold check\n",
    "            if(current_minmax['minmax'] != next_minmax['minmax']):\n",
    "                percentage_change = 100 * \\\n",
    "                    float(abs(next_minmax_value - current_minmax_value) /\n",
    "                            current_minmax_value)\n",
    "\n",
    "                # If threshold fails (i.e. if the difference between the mark_price of the current and next minmax values is less than the given threshold),\n",
    "                # then delete the next minmax\n",
    "                if(percentage_change < THRESHOLD_PERCENTAGE):\n",
    "                    # Remove the next min/max value from being a min/max value, since the mark_price difference from the current index is not large enough\n",
    "                    pd_data.at[next_minmax_index,\n",
    "                                \"minmax\"] = NEITHER_FLAG\n",
    "                    subset = subset.drop(index=next_minmax_index)\n",
    "\n",
    "                # Otherwise, exit the loop! Threshold passed\n",
    "                else:\n",
    "                    diff_greater_than_threshold = True\n",
    "\n",
    "            # If the current value and next value in the subset are both MIN, then keep the lowest MIN value\n",
    "            elif(current_minmax['minmax'] == 1 and next_minmax['minmax'] == 1):\n",
    "                if(current_minmax_value <= next_minmax_value):\n",
    "                    pd_data.at[next_minmax_index,\n",
    "                                \"minmax\"] = NEITHER_FLAG\n",
    "                    subset = subset.drop(index=next_minmax_index)\n",
    "                else:\n",
    "                    # The current minmax is getting deleted for use the the next_minmax row will replace it\n",
    "                    current_minmax = next_minmax\n",
    "                    pd_data.at[current_minmax_index,\n",
    "                                \"minmax\"] = NEITHER_FLAG\n",
    "                    subset = subset.drop(\n",
    "                        index=current_minmax_index)\n",
    "            # If the current value and next value in the subset are both MAX, then keep the highest MAX value\n",
    "            elif(current_minmax['minmax'] == 2 and next_minmax['minmax'] == 2):\n",
    "                if(current_minmax_value >= next_minmax_value):\n",
    "                    pd_data.at[next_minmax_index,\n",
    "                                \"minmax\"] = NEITHER_FLAG\n",
    "                    subset = subset.drop(index=next_minmax_index)\n",
    "                else:\n",
    "                    # The current minmax is getting deleted for use the the next_minmax row will replace it\n",
    "                    current_minmax = next_minmax\n",
    "                    pd_data.at[current_minmax_index,\n",
    "                                \"minmax\"] = NEITHER_FLAG\n",
    "                    subset = subset.drop(\n",
    "                        index=current_minmax_index)\n",
    "            else:\n",
    "                print(\n",
    "                    \"ERROR!!! SHOULD NEVER SEE THIS! Logic failed in minmaxThresholdCheck\")\n",
    "\n",
    "            # reset subSetSize\n",
    "            subsetSize = subset.shape[0]\n",
    "\n",
    "        subset_row_counter = subset_row_counter + 1\n",
    "\n",
    "    return pd_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample data to every 30 seconds (exactly) using linear interpolation and Undersample the entire     on those 30\n",
    "\n",
    "data = df_train.compute()\n",
    "# Gapsize for spliting data\n",
    "GAP_SIZE_MINUTES = 7\n",
    "RESAMPLE_PERIOD = '30S'\n",
    "# INTERPOLATION_METHOD = 'linear'\n",
    "\n",
    "\n",
    "data_split = splitDataByGaps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled = pd.DataFrame(columns=training_columns)\n",
    "for data in data_split:\n",
    "    dataReducedCol = data.drop(\"datetimeNotTheIndex\", axis=1)\n",
    "    # dataReducedCol = data[training_columns]\n",
    "    dataResamples = resampleAndInterpolate(dataReducedCol)\n",
    "    data_resampled = pd.concat([data_resampled, dataResamples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    }
   ],
   "source": [
    "# Regenerate the \"datetimeNotTheIndex\" column for use in the minmax calculations\n",
    "data_resampled[\"datetimeNotTheIndex\"] = data_resampled.index\n",
    "print(type(data_resampled.index))\n",
    "data_resampled_dask = dd.from_pandas(data_resampled, npartitions=8)\n",
    "data_resampled_dask = generateMinmMaxColumn(data_resampled_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['mark_price', 'ask_price', 'bid_price', 'spread',\n",
       "       'mark_price_10T_velocity', 'mark_price_60T_velocity',\n",
       "       'mark_price_1440T_velocity', 'mark_price_10T_mean',\n",
       "       'mark_price_60T_mean', 'mark_price_1440T_mean', 'mark_price_10T_std',\n",
       "       'mark_price_60T_std', 'mark_price_1440T_std',\n",
       "       'mark_price_10T_acceleration_for_10T_velocity',\n",
       "       'mark_price_60T_acceleration_for_60T_velocity', 'datetimeNotTheIndex',\n",
       "       'min', 'max', 'minmax'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "data_resampled_dask.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Delayed('int-a8da99d6-ad78-4609-bed5-b743f5351a07'), 19)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "data_resampled_dask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "type(data_resampled_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}