{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd02db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, progress\n",
    "from dask import delayed\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from scipy import signal\n",
    "from dask.dataframe.utils import make_meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:58739' processes=8 threads=16, memory=7.45 GiB>"
      ],
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:58739</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>8</li>\n  <li><b>Cores: </b>16</li>\n  <li><b>Memory: </b>7.45 GiB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "client = Client(n_workers=8, threads_per_worker=2, memory_limit='1GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE_CRITICAL_POINTS = .8 #percentage of MIN and MAX data devoted to training\n",
    "NEITHER_SIZE_MULTIPLE = 10 #Size of the non-critical point data set in multiples of the critical-point dataset size (i.e. for undersampling the non-critical point dataset)\n",
    "TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled_dask = dd.read_csv(\"DataFromDeepLearningProcessing/DOGE_Deep_2021-04-16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['datetime', 'mark_price', 'ask_price', 'bid_price', 'spread',\n",
       "       'mark_price_10T_velocity', 'mark_price_60T_velocity',\n",
       "       'mark_price_1440T_velocity', 'mark_price_10T_mean',\n",
       "       'mark_price_60T_mean', 'mark_price_1440T_mean', 'mark_price_10T_std',\n",
       "       'mark_price_60T_std', 'mark_price_1440T_std',\n",
       "       'mark_price_10T_acceleration_for_10T_velocity',\n",
       "       'mark_price_60T_acceleration_for_60T_velocity', 'datetimeNotTheIndex',\n",
       "       'min', 'max', 'minmax'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data_resampled_dask.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_resampled_dask = dd.read_csv(\"DOGE_Deep_2021-04-16.csv\")\n",
    "data_resampled_dask[\"datetime\"] = dd.to_datetime(data_resampled_dask[\"datetime\"])\n",
    "data_resampled_dask[\"datetimeNotTheIndex\"] = dd.to_datetime(\n",
    "    data_resampled_dask[\"datetimeNotTheIndex\"])\n",
    "\n",
    "data_resampled_dask = data_resampled_dask.set_index(\"datetime\", sorted=True)\n",
    "\n",
    "training_columns = ['mark_price', 'ask_price', 'bid_price', 'spread',\n",
    "                    'mark_price_10T_velocity', 'mark_price_60T_velocity',\n",
    "                    'mark_price_1440T_velocity', 'mark_price_10T_mean',\n",
    "                    'mark_price_60T_mean', 'mark_price_1440T_mean', 'mark_price_10T_std',\n",
    "                    'mark_price_60T_std', 'mark_price_1440T_std',\n",
    "                    'mark_price_10T_acceleration_for_10T_velocity',\n",
    "                    'mark_price_60T_acceleration_for_60T_velocity', \"minmax\"]\n",
    "\n",
    "data_resampled_dask = data_resampled_dask[training_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_indices = np.array(data_resampled_dask[data_resampled_dask[\"minmax\"] == 1].index.compute().tolist())\n",
    "max_indices = np.array(data_resampled_dask[data_resampled_dask[\"minmax\"] == 2].index.compute().tolist())\n",
    "neither_indices = np.array(data_resampled_dask[data_resampled_dask[\"minmax\"] == 0].index.compute().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_resampled_dask.drop(\"minmax\", axis=1).to_dask_array().compute()\n",
    "Y = data_resampled_dask[\"minmax\"].to_dask_array().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "559972"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Size: 447977\nTest Size: 111995\n"
     ]
    }
   ],
   "source": [
    "#The level 1 train/test split should NOT be shuffled! We want to test the final model on unshuffled data\n",
    "SpliteIndex = int(len(Y)*TRAIN_SIZE_CRITICAL_POINTS)\n",
    "X_train_level_1 = X[:SpliteIndex, :]\n",
    "Y_train_level_1 = Y[:SpliteIndex]\n",
    "\n",
    "X_test_level_1 = X[SpliteIndex:, :]\n",
    "Y_test_level_1 = Y[SpliteIndex:]\n",
    "\n",
    "print(\"Train Size: \" + str(len(Y_train_level_1)))\n",
    "print(\"Test Size: \" + str(len(Y_test_level_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "minIndices = np.where(Y_train_level_1 == 1)[0]\n",
    "minIndices = minIndices[np.where(minIndices >= TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE)] #only take indices above TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE (i.e. min window size). Also remove final index, if present, since cannot build the window off that. Also remove final index, if present, since cannot build the window off that\n",
    "\n",
    "maxIndices = np.where(Y_train_level_1 == 2)[0]\n",
    "maxIndices = maxIndices[np.where(maxIndices >= TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE)]   #Only take indices above TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE (i.e. min window size). Also remove final index, if present, since cannot build the window off that\n",
    "\n",
    "neitherIndices = np.where(Y_train_level_1 == 0)[0]\n",
    "neitherIndices = neitherIndices[np.where(neitherIndices >= TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE)] #Only take indices above TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE (i.e. min window size). Also remove final index, if present, since cannot build the window off that\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n3709\n3710\n440438\n"
     ]
    }
   ],
   "source": [
    "print(type(minIndices))\n",
    "print(len(minIndices))\n",
    "print(len(maxIndices))\n",
    "print(len(neitherIndices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(minIndices)\n",
    "np.random.shuffle(maxIndices)\n",
    "np.random.shuffle(neitherIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([267023, 230739, 375796, ..., 178677, 443434, 318853], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "minIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplitAClass(indexArray, splitIndex, endIndex):\n",
    "    print(splitIndex, endIndex)\n",
    "    if(np.isnan(endIndex)):\n",
    "        Train= indexArray[:splitIndex]\n",
    "        Test = indexArray[splitIndex:]\n",
    "    else:\n",
    "        Train= indexArray[:splitIndex]\n",
    "        Test = indexArray[splitIndex:endIndex]\n",
    "    print(\"Train Size: \" + str(len(Train)))\n",
    "    print(\"Test Size: \" + str(len(Test)))\n",
    "\n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "array len: 3709\nsplitIndex: 2967\n2967 nan\nTrain Size: 2967\nTest Size: 742\n\narray len: 3710\nsplitIndex: 2968\n2968 nan\nTrain Size: 2968\nTest Size: 742\n\narray len: 440438\nsplitIndex: 47480\n47480 59350\nTrain Size: 47480\nTest Size: 11870\n\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "minSplitIndex = int(len(minIndices)*TRAIN_SIZE_CRITICAL_POINTS)\n",
    "maxSplitIndex = int(len(maxIndices)*TRAIN_SIZE_CRITICAL_POINTS)\n",
    "neitherEndIndex = int((minSplitIndex+maxSplitIndex)*NEITHER_SIZE_MULTIPLE)\n",
    "neitherSplitIndex = int(neitherEndIndex*TRAIN_SIZE_CRITICAL_POINTS)\n",
    "for theIndexArray, splitIndex, endIndex in zip(\n",
    "    [minIndices, maxIndices, neitherIndices],\n",
    "    [minSplitIndex, maxSplitIndex, neitherSplitIndex], \n",
    "    [np.nan, np.nan, neitherEndIndex]):\n",
    "    print(\"array len: \" + str(len(theIndexArray)))\n",
    "    print(\"splitIndex: \" + str(splitIndex))\n",
    "    trainTemp, testTemp = trainTestSplitAClass(theIndexArray, splitIndex, endIndex)\n",
    "\n",
    "    train_list.append(trainTemp)\n",
    "    test_list.append(testTemp)\n",
    "    print(\"\")\n",
    "\n",
    "TrainIndices = np.append(train_list[0], train_list[1], axis=0)\n",
    "TrainIndices = np.append(TrainIndices, train_list[2], axis=0)\n",
    "np.random.shuffle(TrainIndices)\n",
    "\n",
    "TestIndices = np.append(test_list[0], test_list[1], axis=0)\n",
    "TestIndices = np.append(TestIndices, test_list[2], axis=0)\n",
    "np.random.shuffle(TestIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWindowsTrain = len(TrainIndices)\n",
    "numColumns = X.shape[1]\n",
    "X_Train = np.zeros([numWindowsTrain, TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE, numColumns])\n",
    "Y_Train = np.empty(shape=numWindowsTrain, dtype=np.int32)\n",
    "for index, windowIndex in zip(range(0, len(TrainIndices)), TrainIndices):\n",
    "    #The final row of of the window needs to include windowIndex, so build the start and stop indices accordingly\n",
    "    windowStartIndex = windowIndex - TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE + 1\n",
    "    \n",
    "    #If the windowIndex happens to the be final index in the X array, then handle that situation\n",
    "    if(windowIndex == len(X)-1):\n",
    "        X_Test[index] = X[windowStartIndex:, :]\n",
    "    else: #This is normal situation (i.e. windowIndex is not the final index in the array)\n",
    "        windowEndIndex = windowIndex + 1\n",
    "        X_Train[index] = X[windowStartIndex:windowEndIndex, :]\n",
    "    Y_Train[index] = Y[windowIndex] #Take hte label from The final row in the window\n",
    "\n",
    "X_Train = da.from_array(X_Train) \n",
    "Y_Train = da.from_array(Y_Train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWindowsTest = len(TestIndices)\n",
    "numColumns = X.shape[1]\n",
    "X_Test = np.zeros([numWindowsTest, TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE, numColumns])\n",
    "Y_Test = np.empty(shape=numWindowsTest, dtype=np.int32)\n",
    "for index, windowIndex in zip(range(0, len(TestIndices)), TestIndices):\n",
    "    #The final row of of the window needs to include windowIndex, so build the start and stop indices accordingly\n",
    "    windowStartIndex = windowIndex - TRAIN_TEST_SPLIT__MIN_WINDOW_SIZE + 1\n",
    "    \n",
    "    #If the windowIndex happens to the be final index in the X array, then handle that situation\n",
    "    if(windowIndex == len(X)-1):\n",
    "        X_Test[index] = X[windowStartIndex:, :]\n",
    "    else: #This is normal situation (i.e. windowIndex is not the final index in the array)\n",
    "        windowEndIndex = windowIndex + 1\n",
    "        X_Test[index] = X[windowStartIndex:windowEndIndex, :]\n",
    "    Y_Test[index] = Y[windowIndex] #Take the label from The final row in the window\n",
    "\n",
    "X_Test = da.from_array(X_Test)\n",
    "Y_Test = da.from_array(Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(53415, 120, 15)\n(53415,)\n(13354, 120, 15)\n(13354,)\n<class 'dask.array.core.Array'>\n"
     ]
    }
   ],
   "source": [
    "print(X_Train.shape)\n",
    "print(Y_Train.shape)\n",
    "print(X_Test.shape)\n",
    "print(Y_Test.shape)\n",
    "print(type(X_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"DataFromDeepLearningProcessing/DODGE/X_Train\"\n",
    "if(not os.path.exists(dir)):\n",
    "            os.makedirs(dir)\n",
    "da.to_npy_stack(dir, X_Train, axis=0)\n",
    "\n",
    "dir = \"DataFromDeepLearningProcessing/DODGE/Y_Train\"\n",
    "if(not os.path.exists(dir)):\n",
    "            os.makedirs(dir)\n",
    "da.to_npy_stack(dir, Y_Train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"DataFromDeepLearningProcessing/DODGE/X_Test\"\n",
    "if(not os.path.exists(dir)):\n",
    "            os.makedirs(dir)\n",
    "da.to_npy_stack(dir, X_Test, axis=0)\n",
    "\n",
    "dir = \"DataFromDeepLearningProcessing/DODGE/Y_Test\"\n",
    "if(not os.path.exists(dir)):\n",
    "            os.makedirs(dir)\n",
    "da.to_npy_stack(dir, Y_Test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}